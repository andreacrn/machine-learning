{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMqLb-QZM_A5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import itertools\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from threading import Lock\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmanLR-YNEWo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ARuO_6BNGMQ"
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 30\n",
    "MEDIUM_SIZE = 30\n",
    "BIGGER_SIZE = 30\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=(15,8))\n",
    "plt.rc('lines', linewidth=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCW9Za2egesm"
   },
   "source": [
    "##Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnyynTG8ZKY7"
   },
   "source": [
    "Load the MONK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kv3wziflFV-t"
   },
   "outputs": [],
   "source": [
    "header=['class','head_shape','body_shape','is_smiling','holding','jacket_color','has_tie','ID']\n",
    "\n",
    "m3_train = pd.read_csv(\"./MONK/monks-3.train\", header=None, delimiter=' ', skipinitialspace=True,\n",
    "                           names=header)\n",
    "m3_test = pd.read_csv(\"./MONK/monks-3.test\", header=None, delimiter=' ', skipinitialspace=True, \n",
    "                           names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjzKux2aFeY4"
   },
   "outputs": [],
   "source": [
    "print('n. record:', len(m3_train))\n",
    "m3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuXV-Ap4FiCK"
   },
   "outputs": [],
   "source": [
    "print('n. record:', len(m3_test))\n",
    "m3_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vymdp833ZaSx"
   },
   "source": [
    "Convert ID column in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xx2WqZ2FmrJ"
   },
   "outputs": [],
   "source": [
    "index_train=[]\n",
    "index_test=[]\n",
    "for id in m3_train['ID']:\n",
    "  index_train.append(int(id.split('_')[1]))\n",
    "for id in m3_test['ID']:\n",
    "  index_test.append(int(id.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XgHie0lFrWw"
   },
   "outputs": [],
   "source": [
    "m3_train.index=index_train\n",
    "m3_train.drop('ID', axis=1, inplace=True)\n",
    "m3_test.index=index_test\n",
    "m3_test.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQoZBEsJF03r"
   },
   "outputs": [],
   "source": [
    "m3_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MWNaKzuZg4E"
   },
   "source": [
    "One-hot encoding of categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7h-xo39F3tJ"
   },
   "outputs": [],
   "source": [
    "todummy=[c for c in m3_train.columns if c not in ['class']]\n",
    "\n",
    "m3_train= pd.get_dummies(m3_train, columns=todummy)\n",
    "m3_test= pd.get_dummies(m3_test, columns=todummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MLZam5aGAY6"
   },
   "outputs": [],
   "source": [
    "m3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU3xx-pZGCps"
   },
   "outputs": [],
   "source": [
    "col=[c for c in m3_train.columns if c!='class']\n",
    "\n",
    "x_train= m3_train[col].values\n",
    "y_train= m3_train['class'].values\n",
    "\n",
    "x_test= m3_test[col].values\n",
    "y_test= m3_test['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQTqzZMqGIi_"
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1_wcU7uGJoM"
   },
   "source": [
    "##KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyatx9HfZx0k"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGLPXUZqYF4H"
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': range(2,80),\n",
    "              'weights':['uniform','distance'],\n",
    "              'p': [1,2]} \n",
    "\n",
    "\n",
    "Grid_KNN = GridSearchCV(KNeighborsClassifier(), \n",
    "                         param_grid, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "\n",
    "Grid_fit = Grid_KNN.fit(x_train, y_train)\n",
    "report(Grid_fit.cv_results_, n_top=5)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5kpoMtrYmmx"
   },
   "outputs": [],
   "source": [
    "report(Grid_fit.cv_results_, n_top=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEf-h7rdaB2C"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBwAMA1AZp-k"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors= 69, p= 1, weights= 'distance')\n",
    "model=model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WuynwgmaR1e"
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "print('Training accuracy:')\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0dVin6_aNGl"
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "print('Test accuracy:')\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZPQbrPgVyao"
   },
   "source": [
    "## LBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8AAuFqnaszc"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msIGd3uo0b2N"
   },
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('lbe',PolynomialFeatures()),('ridge',RidgeClassifier(random_state=0))])\n",
    "param_grid={\n",
    "    'lbe__degree':[2, 3, 4, 5, 6],\n",
    "    'ridge__solver':['saga'],\n",
    "    'ridge__alpha':[100,10, 1, 0, 0.1, 0.01,0.001],\n",
    "    'lbe__interaction_only':[True,False]\n",
    "}\n",
    "\n",
    "grid_search= GridSearchCV(pipe, param_grid=param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0), verbose=4)\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPUIXpXTahGW"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Gg5juy0fuw4"
   },
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('lbe',PolynomialFeatures(degree=4,interaction_only=True)),('ridge',RidgeClassifier(alpha=100, solver='saga', random_state=0))])\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KogmgAG7lmbi"
   },
   "outputs": [],
   "source": [
    "y_pred_train= pipe.predict(x_train)\n",
    "print('Training accuracy:')\n",
    "accuracy_score(y_train, y_pred_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4G1yCehlmbj"
   },
   "outputs": [],
   "source": [
    "y_pred= pipe.predict(x_test)\n",
    "print('Test accuracy:')\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYwpTZewHeoQ"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6torVe-5ax61"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr7FoQxqzUYP"
   },
   "outputs": [],
   "source": [
    "param_grid =[ \n",
    "    {\n",
    "    'C':[0.1, 1, 10, 100,1000], \n",
    "    'kernel':[ 'linear']\n",
    "    },\n",
    "    {\n",
    "    'C':[0.1, 1, 10, 100,1000],\n",
    "    'gamma':['scale','auto'], \n",
    "    'kernel':['rbf']\n",
    "     },\n",
    "    {\n",
    "    'C':[0.1, 1, 10, 100,1000],\n",
    "    'gamma':['scale','auto'], \n",
    "    'kernel':[ 'poly'],\n",
    "     'degree': [2,3,4,5,6]\n",
    "     }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSu16Ama1o_u"
   },
   "outputs": [],
   "source": [
    "Grid_SVM = GridSearchCV(SVC(), \n",
    "                         param_grid, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "\n",
    "Grid_fit = Grid_SVM.fit(x_train, y_train)\n",
    "report(Grid_fit.cv_results_,n_top=5)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VBHr0wda0QT"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXVqxQlh4Bqj"
   },
   "outputs": [],
   "source": [
    "model = SVC(C=0.1, kernel='linear')\n",
    "model=model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsE8v8aT6WQt"
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "print('Training accuracy:')\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flYgbVkt6YCQ"
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "print('Test accuracy:')\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StaAtzOvqLtd"
   },
   "source": [
    "##Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34BiLWPmbFR-"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIDDXZv0qLtd"
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(5,30,5),\n",
    "              'n_estimators':[100],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_split': range(5,40,5),\n",
    "              'min_samples_leaf':range(5,40,5),\n",
    "              'max_features': range(2,18,3),\n",
    "              'bootstrap' : [True, False]}\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6cCtiNYqLte"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=0), param_grid=param_grid, \n",
    "                           cv=StratifiedKFold(5), scoring='accuracy')\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1VueQ6KbIdn"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1eCCr3RqLte"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=25, random_state=0, n_estimators=100, criterion='gini', min_samples_split=15, min_samples_leaf=5,\n",
    " max_features = 17, bootstrap=True)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IRCANTAqLte"
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(x_train)\n",
    "print('Training accuracy')\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKAF9m-aqLte"
   },
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(x_test)\n",
    "print('Test accuracy')\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXfL2RyukVRM"
   },
   "source": [
    "## NN + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1dzkEzxHIpM"
   },
   "source": [
    "Next we define **build_model** function in order to build our Neural Network. In this function we use:\n",
    "\n",
    "*   A seed to get reproducible results. \n",
    "*   L2 reguralization term to loss function\n",
    "*   SGD optimizer to train our NN\n",
    "*   MSE as loss\n",
    "*   Accuracy as metric\n",
    "\n",
    "For this task it is good enough an 1 hidden layer architecture, 17 input unit and 1 output unit with sigmoid activation function dealing with a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzV9NHzVqLtX"
   },
   "outputs": [],
   "source": [
    "def build_model(weight_init=0.2, weight_distr=0, activ='tanh', unit=4, eta=0.2, alpha=0.5, lambd=0):\n",
    "  \n",
    "  tf.random.set_seed(0)  \n",
    "    \n",
    "  if weight_distr==0:\n",
    "    init= tf.keras.initializers.RandomUniform(minval=-weight_init, maxval=weight_init)\n",
    "  elif weight_distr==1:\n",
    "    init= tf.keras.initializers.RandomNormal(mean=0., stddev=weight_init)\n",
    "  else:\n",
    "    init= tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "  reg= tf.keras.regularizers.l2(l2=lambd)\n",
    "\n",
    "  model= tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(17,))\n",
    "  model.add(tf.keras.layers.Dense(unit, activation=activ, kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "\n",
    "  loss= tf.keras.losses.MeanSquaredError()\n",
    "  opt= tf.keras.optimizers.SGD(learning_rate=eta, momentum=alpha, nesterov=False)\n",
    "  metric= tf.keras.metrics.BinaryAccuracy()\n",
    "  model.compile(loss=loss, \n",
    "                optimizer=opt,\n",
    "                metrics=[metric])\n",
    "  \n",
    "  print(model.get_weights())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Glcc3U2GqLtZ"
   },
   "source": [
    "Next we define our grid search which is parallelized on single CV splits' \n",
    "fitting using Futures class from Concurrent library. Model building is made sequentially acquiring a lock; it is necessary to guarantee same weights initializing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6O8y6wmqLtZ"
   },
   "outputs": [],
   "source": [
    "def parallel_cv(list_split, iter, d, x_train, y_train, lock):\n",
    "    \n",
    "  lock.acquire()\n",
    "  try:\n",
    "    model= build_model(**d)\n",
    "  finally:\n",
    "    lock.release()\n",
    "\n",
    "  x_train_cv, x_val_cv, y_train_cv, y_val_cv=  x_train[list_split[iter,0]], x_train[list_split[iter,1]], y_train[list_split[iter,0]], y_train[list_split[iter,1]]\n",
    "  res= model.fit(x_train_cv, y_train_cv, epochs=400, batch_size=len(x_train_cv), validation_data=(x_val_cv,y_val_cv))\n",
    "\n",
    "  return (res.history['val_loss'][-1], res.history['val_binary_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiZ2iPX7qLta"
   },
   "outputs": [],
   "source": [
    "def grid_search(x_train, y_train, param_grid, fold):\n",
    "  totale_iter= 1\n",
    "  for _,value in param_grid.items():\n",
    "    totale_iter= totale_iter*len(value)\n",
    "\n",
    "  split= fold.split(x_train, y_train)\n",
    "  list_split=[]\n",
    "  for train_index, test_index in split:\n",
    "    list_split.append([train_index,test_index])\n",
    "  list_split=np.array(list_split,dtype=object)\n",
    "\n",
    "  iter=0\n",
    "  cv_results=[]\n",
    "  for params in itertools.product(*[l for l in param_grid.values()]):\n",
    "    d= dict(zip(param_grid.keys(), params))\n",
    "    \n",
    "    accuracy=[]\n",
    "    losses=[]\n",
    "    future=[]\n",
    "    \n",
    "    lock= Lock()\n",
    "    \n",
    "    for i in range(0,len(list_split)):\n",
    "      executor=concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "      future.append(executor.submit(parallel_cv, list_split, i, d, x_train, y_train, lock))\n",
    "    \n",
    "    for f in future:\n",
    "      (loss, acc)=f.result()\n",
    "      losses.append(loss)\n",
    "      accuracy.append(acc)\n",
    "    \n",
    "    mean_acc= np.mean(accuracy)\n",
    "    std_acc= np.std(accuracy)\n",
    "    d['mean_val_acc']= mean_acc\n",
    "    d['std_val_acc']= std_acc\n",
    "\n",
    "    mean_loss= np.mean(losses)\n",
    "    std_loss= np.std(losses)\n",
    "    d['mean_val_loss']= mean_loss\n",
    "    d['std_val_loss']= std_loss\n",
    "\n",
    "\n",
    "    \n",
    "    cv_results.append(d)\n",
    "    iter=iter+1\n",
    "    print('ITERAZIONE NUMERO ' + str(iter)+ '   su '+ str(totale_iter)+ ' totali')\n",
    "  \n",
    "  return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tYvh4ONqLta"
   },
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'weight_init': [0.3,0.4],\n",
    "    'weight_distr': [0,1],\n",
    "    'unit': [3,4,5],\n",
    "    'eta': [0.1,0.3,0.5],\n",
    "    'alpha': [0.3,0.5,0.7],\n",
    "    'lambd': [0.01,0.03,0.05],\n",
    "    'activ': ['relu']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdLNzMUOqLta"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results= grid_search(x_train, y_train, param_grid, fold=StratifiedKFold(n_splits=4, shuffle=True, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQREmnNaqLtb"
   },
   "outputs": [],
   "source": [
    "cv_results         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sB15nv42qLtb"
   },
   "outputs": [],
   "source": [
    "sorted_result = (sorted(cv_results, key = lambda i: (i['mean_val_loss'], i['std_val_loss'])))\n",
    "best_5_result=sorted_result[:20]\n",
    "best_5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zs0slu2VqLtb"
   },
   "outputs": [],
   "source": [
    "best_model_par=best_5_result[0]\n",
    "best_model_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9dT3hgeqLtc"
   },
   "outputs": [],
   "source": [
    "best_model_par={'weight_init': 0.3,\n",
    "  'weight_distr': 0,\n",
    "  'unit': 3,\n",
    "  'eta': 0.3,\n",
    "  'alpha': 0.3,\n",
    "  'lambd': 0.01,\n",
    "  'activ': 'relu',\n",
    "  'mean_val_acc': 0.9336021393537521,\n",
    "  'std_val_acc': 0.07828950949927369,\n",
    "  'mean_val_loss': 0.15059752762317657,\n",
    "  'std_val_loss': 0.046077852680874255}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Dd8HBf4qLtc"
   },
   "source": [
    "Final retraining on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtpQURmWqLtc"
   },
   "outputs": [],
   "source": [
    "d=best_model_par\n",
    "model_best_final= build_model(weight_init=d['weight_init'], weight_distr=d['weight_distr'], activ=d['activ'], unit=d['unit'], eta=d['eta'], alpha=d['alpha'], lambd=d['lambd'])\n",
    "test=(x_test,y_test)          \n",
    "\n",
    "result_best=model_best_final.fit(x=x_train, y=y_train, epochs=400, batch_size=len(x_train),shuffle=True, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WU2Fvd7nqLtc"
   },
   "outputs": [],
   "source": [
    "print('Training Accuracy')\n",
    "\n",
    "model_best_final.evaluate(x_train, y_train, batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FC4ThoRgqLtc"
   },
   "outputs": [],
   "source": [
    "print('Test Accuracy')\n",
    "\n",
    "model_best_final.evaluate(x_test, y_test, batch_size=(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKvujSsZqLtd"
   },
   "outputs": [],
   "source": [
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=(15,8))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(result_best.history['binary_accuracy'])\n",
    "plt.plot(result_best.history['val_binary_accuracy'], linestyle='--')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(result_best.history['loss'])\n",
    "plt.plot(result_best.history['val_loss'], linestyle='--')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox1lIAR6g-xK"
   },
   "source": [
    "##NN no reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDsw9V1XlUGQ"
   },
   "source": [
    "Next we define **build_model** function in order to build our Neural Network. In this function we use:\n",
    "\n",
    "*   A seed to get reproducible results. \n",
    "*   L2 reguralization term to loss function\n",
    "*   SGD optimizer to train our NN\n",
    "*   MSE as loss\n",
    "*   Accuracy as metric\n",
    "\n",
    "For this task it is good enough an 1 hidden layer architecture, 17 input unit and 1 output unit with sigmoid activation function dealing with a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsedssv6GT9t"
   },
   "outputs": [],
   "source": [
    "def build_model(weight_init=0.2, weight_distr=0, activ='tanh', unit=4, eta=0.2, alpha=0.5, lambd=0):\n",
    "  \n",
    "  tf.random.set_seed(0)  \n",
    "    \n",
    "  if weight_distr==0:\n",
    "    init= tf.keras.initializers.RandomUniform(minval=-weight_init, maxval=weight_init)\n",
    "  elif weight_distr==1:\n",
    "    init= tf.keras.initializers.RandomNormal(mean=0., stddev=weight_init)\n",
    "  else:\n",
    "    init= tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "  reg= tf.keras.regularizers.l2(l2=lambd)\n",
    "\n",
    "  model= tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(17,))\n",
    "  model.add(tf.keras.layers.Dense(unit, activation=activ, kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "\n",
    "  loss= tf.keras.losses.MeanSquaredError()\n",
    "  opt= tf.keras.optimizers.SGD(learning_rate=eta, momentum=alpha, nesterov=False)\n",
    "  metric= tf.keras.metrics.BinaryAccuracy()\n",
    "  model.compile(loss=loss, \n",
    "                optimizer=opt,\n",
    "                metrics=[metric])\n",
    "  \n",
    "  #print(model.get_weights())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM3Wx-RmGpbT"
   },
   "source": [
    "Next we define our grid search which is parallelized on single CV splits' \n",
    "fitting using Futures class from Concurrent library. Model building is made sequentially acquiring a lock; it is necessary to guarantee same weights initializing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnXiBZppDrBO"
   },
   "outputs": [],
   "source": [
    "def parallel_cv(list_split, iter, d, x_train, y_train, lock):\n",
    "    \n",
    "  lock.acquire()\n",
    "  try:\n",
    "    model= build_model(**d)\n",
    "  finally:\n",
    "    lock.release()\n",
    "\n",
    "  x_train_cv, x_val_cv, y_train_cv, y_val_cv=  x_train[list_split[iter,0]], x_train[list_split[iter,1]], y_train[list_split[iter,0]], y_train[list_split[iter,1]]\n",
    "  res= model.fit(x_train_cv, y_train_cv, epochs=400, batch_size=len(x_train_cv), validation_data=(x_val_cv,y_val_cv), verbose=0)\n",
    "\n",
    "  return (res.history['val_loss'][-1], res.history['val_binary_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiPcdPIdGnds"
   },
   "outputs": [],
   "source": [
    "def grid_search(x_train, y_train, param_grid, fold):\n",
    "  totale_iter= 1\n",
    "  for _,value in param_grid.items():\n",
    "    totale_iter= totale_iter*len(value)\n",
    "\n",
    "  split= fold.split(x_train, y_train)\n",
    "  list_split=[]\n",
    "  for train_index, test_index in split:\n",
    "    list_split.append([train_index,test_index])\n",
    "  list_split=np.array(list_split,dtype=object)\n",
    "\n",
    "  iter=0\n",
    "  cv_results=[]\n",
    "  for params in itertools.product(*[l for l in param_grid.values()]):\n",
    "    d= dict(zip(param_grid.keys(), params))\n",
    "    \n",
    "    accuracy=[]\n",
    "    losses=[]\n",
    "    future=[]\n",
    "    \n",
    "    lock= Lock()\n",
    "    \n",
    "    for i in range(0,len(list_split)):\n",
    "      executor=concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "      future.append(executor.submit(parallel_cv, list_split, i, d, x_train, y_train, lock))\n",
    "    \n",
    "    for f in future:\n",
    "      (loss, acc)=f.result()\n",
    "      losses.append(loss)\n",
    "      accuracy.append(acc)\n",
    "    \n",
    "    mean_acc= np.mean(accuracy)\n",
    "    std_acc= np.std(accuracy)\n",
    "    d['mean_val_acc']= mean_acc\n",
    "    d['std_val_acc']= std_acc\n",
    "\n",
    "    mean_loss= np.mean(losses)\n",
    "    std_loss= np.std(losses)\n",
    "    d['mean_val_loss']= mean_loss\n",
    "    d['std_val_loss']= std_loss\n",
    "\n",
    "\n",
    "    \n",
    "    cv_results.append(d)\n",
    "    iter=iter+1\n",
    "    print('ITERAZIONE NUMERO ' + str(iter)+ '   su '+ str(totale_iter)+ ' totali')\n",
    "  \n",
    "  return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-FIx2_gDwSI"
   },
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'weight_init': [0.3,0.4],\n",
    "    'weight_distr': [0,1],\n",
    "    'unit': [3,4,5],\n",
    "    'eta': [0.1,0.3,0.5],\n",
    "    'alpha': [0.3,0.5,0.7],\n",
    "    'lambd': [0],\n",
    "    'activ': ['relu'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoDCxmueG89N"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results= grid_search(x_train, y_train, param_grid, fold=StratifiedKFold(n_splits=4, shuffle=True, random_state=0))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP7po60zHgZW"
   },
   "outputs": [],
   "source": [
    "cv_results           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUhtp2J7H5em"
   },
   "outputs": [],
   "source": [
    "sorted_result = (sorted(cv_results, key = lambda i: (i['mean_val_loss'], i['std_val_loss'])))\n",
    "best_5_result=sorted_result[:20]\n",
    "best_5_result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47v52i2wIVxy"
   },
   "outputs": [],
   "source": [
    "best_model_par=best_5_result[0]\n",
    "best_model_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77-bcL9n7nCf"
   },
   "outputs": [],
   "source": [
    "best_model_par={'activ': 'relu',\n",
    "  'alpha': 0.3,\n",
    "  'eta': 0.3,\n",
    "  'lambd': 0,\n",
    "  'mean_val_acc': 0.9008064419031143,\n",
    "  'mean_val_loss': 0.07044910732656717,\n",
    "  'std_val_acc': 0.06293939023490572,\n",
    "  'std_val_loss': 0.05546023209986266,\n",
    "  'unit': 5,\n",
    "  'weight_distr': 1,\n",
    "  'weight_init': 0.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuEoa8cAHU9x"
   },
   "source": [
    "Final retraining on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOAJqfCvF1BP"
   },
   "outputs": [],
   "source": [
    "d=best_model_par\n",
    "model_best_final= build_model(weight_init=d['weight_init'], weight_distr=d['weight_distr'], activ=d['activ'], unit=d['unit'], eta=d['eta'], alpha=d['alpha'], lambd=d['lambd'])\n",
    "test=(x_test,y_test)          \n",
    "\n",
    "result_best=model_best_final.fit(x=x_train, y=y_train, epochs=400, batch_size=len(x_train),shuffle=True, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9hR-f5ILM8p"
   },
   "outputs": [],
   "source": [
    "print('Training Accuracy')\n",
    "model_best_final.evaluate(x_train, y_train, batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OI-2cpUfKfcA"
   },
   "outputs": [],
   "source": [
    "print('Test Accuracy')\n",
    "\n",
    "model_best_final.evaluate(x_test, y_test, batch_size=(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnvHR6hTuVO-"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(result_best.history['binary_accuracy'])\n",
    "plt.plot(result_best.history['val_binary_accuracy'], linestyle='--')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(result_best.history['loss'])\n",
    "plt.plot(result_best.history['val_loss'], linestyle='--')\n",
    "plt.title('model MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MONK_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
