{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxYpxhwciDAe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  make_scorer\n",
    "import itertools\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from threading import Lock\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import math\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Qu3ZNa0iTZZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHkK7tauf2AQ"
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 30\n",
    "MEDIUM_SIZE = 30\n",
    "BIGGER_SIZE = 30\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=(15,8))\n",
    "plt.rc('lines', linewidth=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yOrdQr0jRsE"
   },
   "source": [
    "##Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKkes4mNrNK8"
   },
   "source": [
    "Load the CUP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGqf46Kdi9Dm"
   },
   "outputs": [],
   "source": [
    "header=['ID','a','b','c','d','e','f', 'g', 'h', 'i', 'j','Class_x', 'Class_y']\n",
    "df = pd.read_csv(\"./CUP/ML-CUP21-TR.csv\", header=None,delimiter=',', skiprows=7,names=header)\n",
    "df.index=df['ID'].values\n",
    "df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jygDUftQjV_a"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg86-v2-nGKt"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BottViv9jl_E"
   },
   "outputs": [],
   "source": [
    "col=[c for c in df.columns if (c!='Class_x' and c!= 'Class_y')]\n",
    "x= df[col].values\n",
    "y= df[['Class_x', 'Class_y']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD3bJU_6rSUF"
   },
   "source": [
    "Training/Test splitting with Hold-out approch (90%-10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ2hWc5Dkjdk"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qO1qA03ril1"
   },
   "source": [
    "MEE definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbFgFShsmAZi"
   },
   "outputs": [],
   "source": [
    "def mean_euclidean_error_tf(y_true, y_pred):\n",
    "    return K.mean(K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DF_p5fbsmobH"
   },
   "outputs": [],
   "source": [
    "def mean_euclidean_error(y_true, y_pred):\n",
    "    return np.mean(np.sqrt(np.sum(np.square(y_pred-y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wC16euOnxoS"
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2GY9TI6oeYl"
   },
   "outputs": [],
   "source": [
    "score = make_scorer(mean_euclidean_error, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5i2Az9hHE7_"
   },
   "source": [
    "Next we define our grid search which is parallelized on single CV splits' \n",
    "fitting using Futures class from Concurrent library. Model building is made sequentially acquiring a lock; it is necessary to guarantee same weights initializing.\n",
    "We also exploit EarlyStopping callback to stop NN training after 50 epochs without improvement on val MEE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8taMpQMHhb2q"
   },
   "outputs": [],
   "source": [
    "def parallel_cv(list_split, iter, d, x_train, y_train, lock, epochs, batch_size):\n",
    "    \n",
    "  lock.acquire()\n",
    "  try:\n",
    "    model= build_model(**d)\n",
    "  finally:\n",
    "    lock.release()\n",
    "\n",
    "  x_train_cv, x_val_cv, y_train_cv, y_val_cv=  x_train[list_split[iter,0]], x_train[list_split[iter,1]], y_train[list_split[iter,0]], y_train[list_split[iter,1]]\n",
    "\n",
    "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_mean_euclidean_error_tf', patience=50)\n",
    "    \n",
    "  res= model.fit(x_train_cv, y_train_cv, epochs=epochs, batch_size=batch_size, \n",
    "                 validation_data=(x_val_cv,y_val_cv), verbose=0, callbacks=[callback])\n",
    "\n",
    "  epoche=np.argmin(res.history['val_mean_euclidean_error_tf']) \n",
    "  print(epoche+1)\n",
    "\n",
    "  return (res.history['val_loss'][epoche], res.history['val_mean_euclidean_error_tf'][epoche],\n",
    "         res.history['mean_euclidean_error_tf'][epoche])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2ka0B5YYjm2"
   },
   "outputs": [],
   "source": [
    "def grid_search(x_train, y_train, param_grid, fold, epochs, batch_size):\n",
    "  totale_iter= 1\n",
    "  for _,value in param_grid.items():\n",
    "    totale_iter= totale_iter*len(value)\n",
    "\n",
    "  split= fold.split(x_train, y_train)\n",
    "  list_split=[]\n",
    "  for train_index, test_index in split:\n",
    "    list_split.append([train_index,test_index])\n",
    "  list_split=np.array(list_split, dtype=object)\n",
    "  \n",
    "  iter=0\n",
    "  cv_results=[]\n",
    "  for params in itertools.product(*[l for l in param_grid.values()]):\n",
    "    d= dict(zip(param_grid.keys(), params))\n",
    "    \n",
    "    euclidean_error=[]\n",
    "    losses=[]\n",
    "    tr_euclidean_error=[]\n",
    "    future=[]\n",
    "    \n",
    "    lock= Lock()\n",
    "    \n",
    "    for i in range(0,len(list_split)):\n",
    "      executor=concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "      future.append(executor.submit(parallel_cv, list_split, i, d, x_train, y_train, lock, epochs, batch_size))\n",
    "    \n",
    "    for f in future:\n",
    "      (loss, euclidean,tr_euclidean)=f.result()\n",
    "      losses.append(loss)\n",
    "      euclidean_error.append(euclidean)\n",
    "      tr_euclidean_error.append(tr_euclidean)\n",
    "    \n",
    "\n",
    "\n",
    "    mean_ecl= np.mean(euclidean_error)\n",
    "    std_euc= np.std(euclidean_error)\n",
    "    d['mean_euclidean_error']= mean_ecl\n",
    "    d['std_euclidean_error']= std_euc\n",
    "\n",
    "    mean_loss= np.mean(losses)\n",
    "    std_loss= np.std(losses)\n",
    "    d['mean_val_loss']= mean_loss\n",
    "    d['std_val_loss']= std_loss\n",
    "    \n",
    "    mean_ecl_tr= np.mean(tr_euclidean_error)\n",
    "    std_eul_tr= np.std(tr_euclidean_error)\n",
    "    d['mean_training_MEE']= mean_ecl_tr\n",
    "    d['std_training_MEE']= std_eul_tr\n",
    "\n",
    "\n",
    "    \n",
    "    cv_results.append(d)\n",
    "    iter=iter+1\n",
    "    print('ITERAZIONE NUMERO ' + str(iter)+ '   su '+ str(totale_iter)+ ' totali')\n",
    "  \n",
    "  return cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVHn0itYl6YZ"
   },
   "source": [
    "##KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyatx9HfZx0k"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2rkVgVTns5A"
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': range(2,200),\n",
    "              'weights':['uniform', 'distance'],\n",
    "              'p': [1, 2]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=0), scoring=score, verbose=4)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEf-h7rdaB2C"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkvMMuJoooNM"
   },
   "outputs": [],
   "source": [
    "knn= KNeighborsRegressor(n_neighbors= 9, p=1, weights='distance')\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H26cdkuMqAwp"
   },
   "outputs": [],
   "source": [
    "y_pred_knn= knn.predict(x_test)\n",
    "mean_euclidean_error(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPFt1c_KqRmB"
   },
   "outputs": [],
   "source": [
    "y_pred_train_knn= knn.predict(x_train)\n",
    "mean_euclidean_error(y_train, y_pred_train_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9QxrOfFqauG"
   },
   "source": [
    "##SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aif87UPPpTtC"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr7FoQxqzUYP"
   },
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    'estimator__C':[0.1, 1, 10, 100], \n",
    "    'estimator__kernel':[ 'linear'],\n",
    "    'estimator__epsilon':[0.01, 0.1, 1, 10]},\n",
    "    {\n",
    "    'estimator__C':[0.1, 1, 10, 100],\n",
    "    'estimator__gamma':['scale','auto'], \n",
    "    'estimator__kernel':['rbf'],\n",
    "    'estimator__epsilon':[0.01, 0.1, 1, 10]},\n",
    "    {\n",
    "    'estimator__C':[0.1, 1, 10, 100],\n",
    "    'estimator__gamma':['scale', 'auto'], \n",
    "    'estimator__kernel':[ 'poly'],\n",
    "    'estimator__degree': [1, 2, 3, 4, 5],\n",
    "    'estimator__epsilon':[0.01, 0.1, 1, 10]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg06bpc7qccF"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(MultiOutputRegressor(SVR()), param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=0), scoring=score, verbose=4)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oV4ZfcMpgCu"
   },
   "source": [
    "Running a finer grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4E5pbP4WtFP"
   },
   "outputs": [],
   "source": [
    "param_grid_1 = {\n",
    "    'estimator__C':np.arange (0, 15, 0.5),\n",
    "    'estimator__gamma':['scale','auto'], \n",
    "    'estimator__kernel':['rbf'],\n",
    "    'estimator__epsilon':np.arange (0, 1.05, 0.05)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCx91K-WW3J9"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(MultiOutputRegressor(SVR()), param_grid_1, cv=KFold(n_splits=5, shuffle=True, random_state=0), scoring=score, verbose=4)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_,n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMJj52F_prGI"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8b5rYP0zmWG"
   },
   "outputs": [],
   "source": [
    "mor= MultiOutputRegressor(SVR(C= 10, epsilon= 0.5, gamma= 'auto', kernel= 'rbf'))\n",
    "mor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Egv2rQqYJ5YQ"
   },
   "outputs": [],
   "source": [
    "y_pred_train= mor.predict(x_train)\n",
    "print('MEE Train: ',mean_euclidean_error(y_train,y_pred_train))\n",
    "y_pred_svm= mor.predict(x_test)\n",
    "print('MEE Test: ',mean_euclidean_error(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80Sx7uZo0K1u"
   },
   "source": [
    "##LBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2acHwYSUp9G3"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pomoQ3ok0MaR"
   },
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('lbe',PolynomialFeatures()),('ridge',Ridge(random_state=0))])\n",
    "param_grid={\n",
    "    'lbe__degree':[2, 3, 4, 5, 6],\n",
    "    'ridge__solver':['saga'],\n",
    "    'ridge__alpha':[10, 1, 0, 0.1, 0.01, 0.001],\n",
    "    'lbe__interaction_only':[True, False]\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9Fdd4Dw0WRE"
   },
   "outputs": [],
   "source": [
    "grid_search= GridSearchCV(pipe, param_grid=param_grid, scoring=score, cv=KFold(n_splits=5, shuffle=True, random_state=0), verbose=4)\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKHMpEMzp59x"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2toe7Gz1EPC"
   },
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('lbe',PolynomialFeatures(degree=4, interaction_only=True)),('ridge',Ridge(alpha=10, solver='saga', random_state=0))])\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5h1hCPfJmVv"
   },
   "outputs": [],
   "source": [
    "y_pred_train= pipe.predict(x_train)\n",
    "print('MEE Train: ',mean_euclidean_error(y_train,y_pred_train))\n",
    "y_pred= pipe.predict(x_test)\n",
    "print('MEE Test: ',mean_euclidean_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JYwg7Gbdjal"
   },
   "source": [
    "##Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0j7tcjkqFyr"
   },
   "source": [
    "Hyper-parameters tuning using GridSearchCV from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl_ja2ped2lH"
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(5,60,5),\n",
    "              'n_estimators':[100],\n",
    "              'min_samples_split': range(2,22,2),\n",
    "              'min_samples_leaf':range(2,22,2),\n",
    "              'max_features': range(2,11,1),\n",
    "              'bootstrap' : [True, False]}\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=0, criterion='squared_error'), param_grid=param_grid, \n",
    "                           cv=KFold(n_splits=5, shuffle=True, random_state=0), scoring=score)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMXJ_gTfqH3o"
   },
   "source": [
    "Model fitting and TR/TS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FznusKVsd2ud"
   },
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100, criterion='squared_error', min_samples_split=2, min_samples_leaf=2,\n",
    " max_features = 3, bootstrap=False)\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFdlE627d2xz"
   },
   "outputs": [],
   "source": [
    "y_pred_train = regr.predict(x_train)\n",
    "mean_euclidean_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52N30N2Vd20B"
   },
   "outputs": [],
   "source": [
    "y_pred_forest = regr.predict(x_test)\n",
    "mean_euclidean_error(y_test, y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii-vSh8yZSzE"
   },
   "source": [
    "##NN SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1dzkEzxHIpM"
   },
   "source": [
    "Next we define **build_model** function in order to build our Neural Network. In this function we use:\n",
    "\n",
    "*   A seed to get reproducible results. \n",
    "*   L2 reguralization term to loss function\n",
    "*   SGD optimizer to train our NN\n",
    "*   MEE as loss and metric\n",
    "\n",
    "For solve this task it is useful to build a multilayer architecture using Tanh activation function for the hidden layers' units. Instead in the 2 output units it is used a linear activation function dealing with the regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bPLfoJVZWav"
   },
   "outputs": [],
   "source": [
    "def build_model(weight_init=0.2, weight_distr=0, activ='relu',layer=1, unit=4, eta=0.2, alpha=0.5, lambd=0):\n",
    "  \n",
    "  tf.random.set_seed(0)  \n",
    "    \n",
    "  if weight_distr==0:\n",
    "    init= tf.keras.initializers.RandomUniform(minval=-weight_init, maxval=weight_init)\n",
    "  elif weight_distr==1:\n",
    "    init= tf.keras.initializers.RandomNormal(mean=0., stddev=weight_init)\n",
    "  else:\n",
    "    init= tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "  reg= tf.keras.regularizers.l2(l2=lambd)\n",
    "\n",
    "\n",
    "  model= tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(10,))\n",
    "  for i in range(layer):\n",
    "    model.add(tf.keras.layers.Dense(unit, activation='tanh', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "  model.add(tf.keras.layers.Dense(2, activation='linear', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "\n",
    "  loss=mean_euclidean_error_tf\n",
    "  opt= tf.keras.optimizers.SGD(learning_rate=eta, momentum=alpha, nesterov=False)\n",
    "  metric=mean_euclidean_error_tf\n",
    "  model.compile(loss=loss, \n",
    "                optimizer=opt,\n",
    "                metrics=[metric])\n",
    "  \n",
    "  #print(model.get_weights())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hgCCcdEZIiN"
   },
   "source": [
    "### Batch mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzN1RnWIrQyG"
   },
   "source": [
    "Hyper-parameters tuning for NN with batch mode. Parameter grids is shown in order from the most general toward more granular ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8Ap_RgDZlQB"
   },
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'weight_init': [0.2 ,0.3, 0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [30, 40],\n",
    "    'layer':[3],\n",
    "    'eta': [0.01, 0.03, 0.05, 0.07],\n",
    "    'alpha': [0.9, 0.95],\n",
    "    'lambd': [0.0005, 0.001, 0.005, 0.01],\n",
    "    'activ': ['tanh']\n",
    "}\n",
    "\n",
    "param_grid={\n",
    "    'weight_init': [0.2,0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [10,20,30,40,50],\n",
    "    'layer':[2,3],\n",
    "    'eta': [0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "    'alpha': [0.8, 0.9, 0.95, 0.975],\n",
    "    'lambd': [0.0005, 0.001, 0.005, 0.01],\n",
    "    'activ': ['tanh']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkD4ekMmicT4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbDC8eoOZlSs"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results= grid_search(x_train, y_train, param_grid, fold=KFold(n_splits=4, shuffle=True, random_state=0), epochs=800, batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7Bx-mxSZlV1"
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xC0L6AtZlY4"
   },
   "outputs": [],
   "source": [
    "sorted_result = (sorted(cv_results, key = lambda i: (i['mean_euclidean_error'], i['std_euclidean_error'])))\n",
    "best_5_result=sorted_result[:5]\n",
    "best_5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsMCRXLrZlbu"
   },
   "outputs": [],
   "source": [
    "best_model_par=best_5_result[0]\n",
    "best_model_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HjzVS4Yrygo"
   },
   "source": [
    "Best parameter combo retrieved from the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eilIiQH7ZleP"
   },
   "outputs": [],
   "source": [
    "best_model_par={'weight_init': 0.4,\n",
    "  'weight_distr': 1,\n",
    "  'unit': 40,\n",
    "  'layer': 3,\n",
    "  'eta': 0.03,\n",
    "  'alpha': 0.95,\n",
    "  'lambd': 0.001,\n",
    "  'activ': 'tanh',\n",
    "  'mean_euclidean_error': 1.050774022936821,\n",
    "  'std_euclidean_error': 0.03191835462576261,\n",
    "  'mean_val_loss': 1.6136361360549927,\n",
    "  'std_val_loss': 0.14172841075355544,\n",
    "  'mean_training_MEE': 0.8342830985784531,\n",
    "  'std_training_MEE': 0.07254623048895122}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R23RMsXer6QL"
   },
   "source": [
    "Then we do a retraining on the whole TR set stopping the NN training when it reaches the mean training loss of the CV fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FrkakyrP3Ep"
   },
   "outputs": [],
   "source": [
    "err=best_model_par['mean_training_MEE']\n",
    "class haltCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('mean_euclidean_error_tf') <=err):\n",
    "            print(\"\\n\\n\\nReached tr value so cancelling training!\\n\\n\\n\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIwOPVAFP_zU"
   },
   "outputs": [],
   "source": [
    "trainingStopCallback = haltCallback()\n",
    "d=best_model_par\n",
    "model_best= build_model(weight_init=d['weight_init'], weight_distr=d['weight_distr'], activ=d['activ'], layer=d['layer'], unit=d['unit'], eta=d['eta'], alpha=d['alpha'], lambd=d['lambd'])\n",
    "\n",
    "val_best=(x_test,y_test)     \n",
    "result_best=model_best.fit(x=x_train, y=y_train, epochs=800, batch_size=(len(x_train)), validation_data=val_best, \n",
    "                           shuffle=True,callbacks=[trainingStopCallback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02F1oXHPupnY"
   },
   "source": [
    "MEE and Loss plot followed by TR and TS prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssZx7bxPQsWO"
   },
   "outputs": [],
   "source": [
    "# summarize history for MEE\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['mean_euclidean_error_tf'])\n",
    "plt.plot(result_best.history['val_mean_euclidean_error_tf'], linestyle='--')\n",
    "plt.title('model MEE')\n",
    "plt.ylabel('MEE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['loss'])\n",
    "plt.plot(result_best.history['val_loss'], linestyle='--')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Y2ONQb2Tenk"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_train, y_train,batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTpX88dmRJ8a"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_test, y_test,batch_size=(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu8bMkqxcPmh"
   },
   "source": [
    "###Mini batch 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXDYprwNu4pM"
   },
   "source": [
    "Hyper-parameters tuning for NN with mini-batch mode of size 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V71RVkiUcSvy"
   },
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'weight_init': [0.2, 0.3, 0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [10,20,30,40,50],\n",
    "    'layer':[2,3],\n",
    "    'eta': [0.0001, 0.0005, 0.001, 0.005, 0.0075, 0.01, 0.025, 0.05],\n",
    "    'alpha':0,\n",
    "    'lambd': [0.0001,0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "    'activ': ['tanh']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVunGjW4cSvy"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results= grid_search(x_train, y_train, param_grid, fold=KFold(n_splits=4, shuffle=True, random_state=0), epochs=800, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFM90V5ccSvy"
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_sthCh8cSvz"
   },
   "outputs": [],
   "source": [
    "sorted_result = (sorted(cv_results, key = lambda i: (i['mean_euclidean_error'], i['std_euclidean_error'])))\n",
    "best_5_result=sorted_result[:5]\n",
    "best_5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Pzs34VEcSvz"
   },
   "outputs": [],
   "source": [
    "best_model_par=best_5_result[0]\n",
    "best_model_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOe5cZi7cSvz"
   },
   "outputs": [],
   "source": [
    "best_model_par={'weight_init': 0.2,\n",
    "  'weight_distr': 1,\n",
    "  'unit': 50,\n",
    "  'layer': 3,\n",
    "  'eta': 0.025,\n",
    "  'alpha':0,\n",
    "  'lambd': 0.0005,\n",
    "  'activ': 'tanh',\n",
    "  'mean_euclidean_error': 1.0905110239982605,\n",
    "  'std_euclidean_error': 0.022719327275489965,\n",
    "  'mean_val_loss': 1.2269698977470398,\n",
    "  'std_val_loss': 0.019988722933869295,\n",
    "  'mean_training_MEE': 1.0076722502708435,\n",
    "  'std_training_MEE': 0.02095401036698643}\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DORc6EJdvMob"
   },
   "source": [
    "Then we do a retraining on the whole TR set stopping the NN training when it reaches the mean training loss of the CV fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wx732-ilT_BB"
   },
   "outputs": [],
   "source": [
    "err=best_model_par['mean_training_MEE']\n",
    "class haltCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('mean_euclidean_error_tf') <=err):\n",
    "            print(\"\\n\\n\\nReached tr value so cancelling training!\\n\\n\\n\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cz1maPgGT_Fl"
   },
   "outputs": [],
   "source": [
    "trainingStopCallback = haltCallback()\n",
    "d=best_model_par\n",
    "model_best= build_model(weight_init=d['weight_init'], weight_distr=d['weight_distr'], activ=d['activ'], layer=d['layer'], unit=d['unit'], eta=d['eta'], alpha=d['alpha'], lambd=d['lambd'])\n",
    "\n",
    "val_best=(x_test,y_test)     \n",
    "result_best=model_best.fit(x=x_train, y=y_train, epochs=800, batch_size=100, validation_data=val_best, \n",
    "                           shuffle=True,callbacks=[trainingStopCallback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wgJeF7WvTaR"
   },
   "source": [
    "MEE and Loss plot followed by TR and TS prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qHicrumUXjh"
   },
   "outputs": [],
   "source": [
    "# summarize history for MEE\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['mean_euclidean_error_tf'])\n",
    "plt.plot(result_best.history['val_mean_euclidean_error_tf'], linestyle=(0, (5, 1)))\n",
    "plt.title('model MEE')\n",
    "plt.ylabel('MEE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['loss'])\n",
    "plt.plot(result_best.history['val_loss'], linestyle='--')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6jJZhWVTvc6"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_train, y_train,batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuDHxUtWU25C"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_test, y_test,batch_size=(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3x-5EL3Vrhq"
   },
   "source": [
    "###Online mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEfWjjFivaAM"
   },
   "source": [
    "Hyper-parameters tuning for NN with online mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYZE9DteVrhr"
   },
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'weight_init': [0.2, 0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [10,20,30,40,50],\n",
    "    'eta': [0.000001,0.000005,0.00001,0.00005,0.0001,0.00025,0.0005],\n",
    "    'alpha':[0],\n",
    "    'layer':[2,3],\n",
    "    'lambd': [0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "    'activ': ['tanh']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6MBIs7aVrhs"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results= grid_search(x_train, y_train, param_grid, fold=KFold(n_splits=4, shuffle=True, random_state=0), epochs=400, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wniMpFywVrhs"
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lzPrvznVrhs"
   },
   "outputs": [],
   "source": [
    "sorted_result = (sorted(cv_results, key = lambda i: (i['mean_euclidean_error'], i['std_euclidean_error'])))\n",
    "best_5_result=sorted_result[:5]\n",
    "best_5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "961-UKL_Vrhs"
   },
   "outputs": [],
   "source": [
    "best_model_par=best_5_result[0]\n",
    "best_model_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atTX3OSLVrhs"
   },
   "outputs": [],
   "source": [
    "best_model_par={'weight_init': 0.2,\n",
    "  'weight_distr': 1,\n",
    "  'unit': 50,\n",
    "  'eta': 0.0005,\n",
    "  'alpha': 0,\n",
    "  'layer': 2,\n",
    "  'lambd': 0.001,\n",
    "  'activ': 'tanh',\n",
    "  'mean_euclidean_error': 1.0894718170166016,\n",
    "  'std_euclidean_error': 0.01959021261526786,\n",
    "  'mean_training_MEE': 0.9664344638586044,\n",
    "  'std_training_MEE': 0.027382713585267594,\n",
    "  'mean_val_loss': 1.2418962121009827,\n",
    "  'std_val_loss': 0.019059742747835607}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3UxsQAoviCG"
   },
   "source": [
    "Then we do a retraining on the whole TR set stopping the NN training when it reaches the mean training loss of the CV fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFTdBjDmVrhs"
   },
   "outputs": [],
   "source": [
    "err=best_model_par['mean_training_MEE']\n",
    "\n",
    "class haltCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('mean_euclidean_error_tf') <=err):\n",
    "            print(\"\\n\\n\\nReached tr value so cancelling training!\\n\\n\\n\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbH1i2eCVrht"
   },
   "outputs": [],
   "source": [
    "trainingStopCallback = haltCallback()\n",
    "d=best_model_par\n",
    "model_best= build_model(weight_init=d['weight_init'], weight_distr=d['weight_distr'], activ=d['activ'], layer=d['layer'], unit=d['unit'], eta=d['eta'], alpha=d['alpha'], lambd=d['lambd'])\n",
    "\n",
    "val_best=(x_test,y_test)     \n",
    "result_best=model_best.fit(x=x_train, y=y_train, epochs=400, batch_size=1, validation_data=val_best, \n",
    "                           shuffle=True,callbacks=[trainingStopCallback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZMbsBT4vrBv"
   },
   "source": [
    "MEE and Loss plot followed by TR and TS prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8gSAT0IVrht"
   },
   "outputs": [],
   "source": [
    "# summarize history for MEE\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['mean_euclidean_error_tf'])\n",
    "plt.plot(result_best.history['val_mean_euclidean_error_tf'], linestyle='--')\n",
    "plt.title('model MEE')\n",
    "plt.ylabel('MEE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['loss'])\n",
    "plt.plot(result_best.history['val_loss'], linestyle='--')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Z__eNoQT7co"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_train, y_train,batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSuNUxydVrht"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_test, y_test,batch_size=(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7QkA-ACPVlq"
   },
   "source": [
    "##ADAM optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mRYqyWRv1HP"
   },
   "source": [
    "Next we define **build_model** also for ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDXXA6sARPhN"
   },
   "outputs": [],
   "source": [
    "def build_model(weight_init=0.2, weight_distr=0, activ='relu',layer=1, unit=4, eta=0.2, alpha=0.5, lambd=0, beta_1=0.9, beta_2=0.999):\n",
    "  \n",
    "  tf.random.set_seed(0)  \n",
    "    \n",
    "  if weight_distr==0:\n",
    "    init= tf.keras.initializers.RandomUniform(minval=-weight_init, maxval=weight_init)\n",
    "  elif weight_distr==1:\n",
    "    init= tf.keras.initializers.RandomNormal(mean=0., stddev=weight_init)\n",
    "  else:\n",
    "    init= tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "  reg= tf.keras.regularizers.l2(l2=lambd)\n",
    "\n",
    "\n",
    "  model= tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(10,))\n",
    "  for i in range(layer):\n",
    "    model.add(tf.keras.layers.Dense(unit, activation='tanh', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "  model.add(tf.keras.layers.Dense(2, activation='linear', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "\n",
    "  loss=mean_euclidean_error_tf\n",
    "  opt= tf.keras.optimizers.Adam(learning_rate=eta, beta_1=beta_1, beta_2=beta_2)\n",
    "  metric=mean_euclidean_error_tf\n",
    "  model.compile(loss=loss, \n",
    "                optimizer=opt,\n",
    "                metrics=[metric])\n",
    "  \n",
    "  #print(model.get_weights())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ixuZd_Yv8y0"
   },
   "source": [
    "Hyper-parameters tuning for NN with ADAM optimizer and batch mode. Parameter grids is shown in order from the most general toward more granular ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLcgN8-kSQTR"
   },
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'weight_init': [0.2, 0.3, 0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [30,40,50],\n",
    "    'layer':[3],\n",
    "    'eta': [0.025],\n",
    "    'beta_1': [0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6],\n",
    "    'beta_2': [0.999, 0.9, 0.8, 0.7, 0.6],\n",
    "    'lambd': [0.00075, 0.0005,  0.001, 0.005],\n",
    "    'activ': ['tanh']\n",
    "}\n",
    "\n",
    "param_grid={\n",
    "    'weight_init': [0.2, 0.3, 0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [20,30,40,50],\n",
    "    'layer':[3],\n",
    "    'eta': [0.0075, 0.01, 0.025],\n",
    "    'beta_1': [0.9, 0.8, 0.7, 0.6],\n",
    "    'beta_2': [0.999],\n",
    "    'lambd': [0.00075, 0.0005,  0.001, 0.005],\n",
    "    'activ': ['tanh']\n",
    "}\n",
    "\n",
    "param_grid={\n",
    "    'weight_init': [0.2, 0.4],\n",
    "    'weight_distr': [1],\n",
    "    'unit': [10,20,30,40,50],\n",
    "    'layer':[2,3],\n",
    "    'eta': [0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
    "    'beta_1': [0.9, 0.8, 0.7, 0.6],\n",
    "    'beta_2': [0.999],\n",
    "    'lambd': [0.0005,  0.001, 0.005,  0.01],\n",
    "    'activ': ['tanh']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0TYNnZ7W2gf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_results= grid_search(x_train, y_train, param_grid, fold=KFold(n_splits=4, shuffle=True, random_state=0), epochs=600, batch_size=len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gomVX3q0Bm3c"
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDlxAWHSTNBq"
   },
   "outputs": [],
   "source": [
    "sorted_result = (sorted(cv_results, key = lambda i: (i['mean_euclidean_error'], i['std_euclidean_error'])))\n",
    "best_5_result=sorted_result[:5]\n",
    "best_5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPbQrmSgTNPn"
   },
   "outputs": [],
   "source": [
    "best_model_par=best_5_result[0]\n",
    "best_model_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6JPjalT2U8Z"
   },
   "outputs": [],
   "source": [
    "best_model_par= {'weight_init': 0.4,\n",
    "  'weight_distr': 1,\n",
    "  'unit': 40,\n",
    "  'layer': 3,\n",
    "  'eta': 0.025,\n",
    "  'beta_1': 0.9,\n",
    "  'beta_2': 0.7,\n",
    "  'lambd': 0.001,\n",
    "  'activ': 'tanh',\n",
    "  'mean_euclidean_error': 1.041769653558731,\n",
    "  'std_euclidean_error': 0.01717042196876029,\n",
    "  'mean_val_loss': 1.3092704713344574,\n",
    "  'std_val_loss': 0.050951337200595484,\n",
    "  'mean_loss_euclidean_error': 0.8765210807323456,\n",
    "  'std_loss_euclidean_error': 0.04217124598293542}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ1xy-DGwJWu"
   },
   "source": [
    "Then we do a retraining on the whole TR set stopping the NN training when it reaches the mean training loss of the CV fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBTFzKHYSXcD"
   },
   "outputs": [],
   "source": [
    "err=best_model_par['mean_training_MEE']\n",
    "\n",
    "class haltCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('mean_euclidean_error_tf') <=err):\n",
    "            print(\"\\n\\n\\nReached tr value so cancelling training!\\n\\n\\n\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "trainingStopCallback = haltCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4hT5blJSXjO"
   },
   "outputs": [],
   "source": [
    "d=best_model_par\n",
    "model_best= build_model(weight_init=d['weight_init'], weight_distr=d['weight_distr'], activ=d['activ'], layer=d['layer'], unit=d['unit'], eta=d['eta'], lambd=d['lambd'], beta_1=d['beta_1'], beta_2=d['beta_2'])\n",
    "\n",
    "\n",
    "val_best=(x_test,y_test)     \n",
    "result_best=model_best.fit(x=x_train, y=y_train, epochs=800, batch_size=len(x_train), validation_data=val_best, \n",
    "                           shuffle=True,callbacks=[trainingStopCallback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL-EqW8XwW7y"
   },
   "source": [
    "MEE and Loss plot followed by TR and TS prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3i7RfEcS0ce"
   },
   "outputs": [],
   "source": [
    "# summarize history for MEE\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['mean_euclidean_error_tf'])\n",
    "plt.plot(result_best.history['val_mean_euclidean_error_tf'], linestyle='--')\n",
    "plt.title('model MEE')\n",
    "plt.ylabel('MEE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(result_best.history['loss'])\n",
    "plt.plot(result_best.history['val_loss'], linestyle='--')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EO7VWIAsXQH1"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_train, y_train,batch_size=(len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFDa_6EZS9-M"
   },
   "outputs": [],
   "source": [
    "model_best.evaluate(x_test, y_test,batch_size=(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6_DS-tjGpz5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nVHn0itYl6YZ",
    "i9QxrOfFqauG",
    "80Sx7uZo0K1u",
    "1JYwg7Gbdjal"
   ],
   "name": "CUP_FINALE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
