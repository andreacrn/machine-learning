{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CwVT2usziiu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import make_scorer\n",
    "import concurrent.futures\n",
    "from threading import Lock\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljo1e11Uzlj8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yOrdQr0jRsE"
   },
   "source": [
    "##Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKkes4mNrNK8"
   },
   "source": [
    "Load the CUP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBQyu92J1Cp_"
   },
   "outputs": [],
   "source": [
    "header=['ID','a','b','c','d','e','f', 'g', 'h', 'i', 'j']\n",
    "blind = pd.read_csv(\"./CUP/ML-CUP21-TS.csv\", header=None,delimiter=',', skiprows=7,names=header)\n",
    "blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akvj7pLS1Vq5"
   },
   "outputs": [],
   "source": [
    "blind.index=blind['ID'].values\n",
    "blind.drop('ID', axis=1, inplace=True)\n",
    "blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGNNbwm12Htp"
   },
   "outputs": [],
   "source": [
    "blind=blind.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGqf46Kdi9Dm"
   },
   "outputs": [],
   "source": [
    "header=['ID','a','b','c','d','e','f', 'g', 'h', 'i', 'j','Class_x', 'Class_y']\n",
    "df = pd.read_csv(\"./CUP/ML-CUP21-TR.csv\", header=None,delimiter=',', skiprows=7,names=header)\n",
    "df.index=df['ID'].values\n",
    "df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jygDUftQjV_a"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg86-v2-nGKt"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BottViv9jl_E"
   },
   "outputs": [],
   "source": [
    "col=[c for c in df.columns if (c!='Class_x' and c!= 'Class_y')]\n",
    "x= df[col].values\n",
    "y= df[['Class_x', 'Class_y']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD3bJU_6rSUF"
   },
   "source": [
    "Training/Test splitting with Hold-out approch (90%-10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ2hWc5Dkjdk"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qO1qA03ril1"
   },
   "source": [
    "MEE definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbFgFShsmAZi"
   },
   "outputs": [],
   "source": [
    "def mean_euclidean_error_tf(y_true, y_pred):\n",
    "    return K.mean(K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9s3Ztrw4fOE"
   },
   "outputs": [],
   "source": [
    "def mean_euclidean_error(y_true, y_pred):\n",
    "    return np.mean(np.sqrt(np.sum(np.square(y_pred-y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84paq2qQXi1Q"
   },
   "outputs": [],
   "source": [
    "score = make_scorer(mean_euclidean_error, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDXXA6sARPhN"
   },
   "outputs": [],
   "source": [
    "def build_model(weight_init=0.2, weight_distr=0, activ='relu',layer=1, unit=4, eta=0.2, alpha=0.5, lambd=0):\n",
    "  \n",
    "  tf.random.set_seed(0)  \n",
    "    \n",
    "  if weight_distr==0:\n",
    "    init= tf.keras.initializers.RandomUniform(minval=-weight_init, maxval=weight_init)\n",
    "  elif weight_distr==1:\n",
    "    init= tf.keras.initializers.RandomNormal(mean=0., stddev=weight_init)\n",
    "  else:\n",
    "    init= tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "  reg= tf.keras.regularizers.l2(l2=lambd)\n",
    "\n",
    "\n",
    "  model= tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(10,))\n",
    "  for i in range(layer):\n",
    "    model.add(tf.keras.layers.Dense(unit, activation='tanh', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "  model.add(tf.keras.layers.Dense(2, activation='linear', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "\n",
    "  loss=mean_euclidean_error_tf\n",
    "  opt= tf.keras.optimizers.SGD(learning_rate=eta, momentum=alpha, nesterov=False)\n",
    "  metric=mean_euclidean_error_tf\n",
    "  model.compile(loss=loss, \n",
    "                optimizer=opt,\n",
    "                metrics=[metric])\n",
    "  \n",
    "  #print(model.get_weights())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R38lyUmjJ6jN"
   },
   "outputs": [],
   "source": [
    "def build_model_Adam(weight_init=0.2, weight_distr=0, activ='relu',layer=1, unit=4, eta=0.2, alpha=0.5, lambd=0, beta_1=0.9, beta_2=0.999, epsilon=0.0000001):\n",
    "  \n",
    "  tf.random.set_seed(0)  \n",
    "    \n",
    "  if weight_distr==0:\n",
    "    init= tf.keras.initializers.RandomUniform(minval=-weight_init, maxval=weight_init)\n",
    "  elif weight_distr==1:\n",
    "    init= tf.keras.initializers.RandomNormal(mean=0., stddev=weight_init)\n",
    "  else:\n",
    "    init= tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "  reg= tf.keras.regularizers.l2(l2=lambd)\n",
    "\n",
    "\n",
    "  model= tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(10,))\n",
    "  for i in range(layer):\n",
    "    model.add(tf.keras.layers.Dense(unit, activation='tanh', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "  model.add(tf.keras.layers.Dense(2, activation='linear', kernel_initializer=init, bias_initializer=init, kernel_regularizer=reg))\n",
    "\n",
    "  loss=mean_euclidean_error_tf\n",
    "  opt= tf.keras.optimizers.Adam(learning_rate=eta, beta_1=beta_1, beta_2=beta_2,epsilon=epsilon)\n",
    "  metric=mean_euclidean_error_tf\n",
    "  model.compile(loss=loss, \n",
    "                optimizer=opt,\n",
    "                metrics=[metric])\n",
    "  \n",
    "  #print(model.get_weights())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJG74vLDLPdz"
   },
   "outputs": [],
   "source": [
    "class haltCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, err):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.err=err\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('mean_euclidean_error_tf') <=self.err):\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlgW9whUzzV8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZBJnlpApbjc"
   },
   "source": [
    "#Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-hpQYJIpmzS"
   },
   "outputs": [],
   "source": [
    "class Voting():\n",
    "\n",
    "  #Voting constructor which takes the best grid's output hyper-parameters for\n",
    "  #the estimators to ensamble\n",
    "  def __init__(self) -> None:\n",
    "      nn_param_batch={\n",
    "          'weight_init': 0.4,\n",
    "          'weight_distr': 1,\n",
    "          'unit': 40,\n",
    "          'layer': 3,\n",
    "          'eta': 0.03,\n",
    "          'alpha': 0.95,\n",
    "          'lambd': 0.001,\n",
    "          'activ': 'tanh',\n",
    "      }\n",
    "      mean_err_batch= 0.8342830985784531\n",
    "      trainingStopCallback_batch = haltCallback(mean_err_batch)\n",
    "\n",
    "\n",
    "      nn_param_adam={\n",
    "          'weight_init': 0.4,\n",
    "          'weight_distr': 1,\n",
    "          'unit': 40,\n",
    "          'layer': 3,\n",
    "          'eta': 0.025,\n",
    "          'beta_1': 0.9,\n",
    "          'beta_2': 0.7,\n",
    "          'lambd': 0.001,\n",
    "          'activ': 'tanh'\n",
    "      }\n",
    "      mean_err_adam= 0.8765210807323456\n",
    "      trainingStopCallback_adam = haltCallback(mean_err_adam)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #estimator definition with best hyper-parameters\n",
    "      self.estimators=[\n",
    "            ('knn', KNeighborsRegressor(n_neighbors= 9, p=1, weights='distance')),\n",
    "            ('batch', KerasRegressor(build_model, **nn_param_batch, epochs=800, shuffle=True, batch_size=len(x_train), verbose=0, callbacks=[trainingStopCallback_batch])),\n",
    "            ('adam', KerasRegressor(build_model_Adam, **nn_param_adam, epochs=800, shuffle=True, batch_size=len(x_train), verbose=0, callbacks=[trainingStopCallback_adam])),\n",
    "            ('forest', RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100, criterion='squared_error', min_samples_split=2, min_samples_leaf=2, \n",
    "                                    max_features = 3, bootstrap=False))\n",
    "      ]\n",
    "      \n",
    "      self.col= [name for (name, estimator) in self.estimators]\n",
    "\n",
    "  #In the predict method we first retrain the base estimators on the whole TR\n",
    "  #And then we use the trained models to predict the TS, building the DataFrame on which we take the mean\n",
    "  def predict(self, X_train, y_train, X_test):\n",
    "      pred_test_x= pd.DataFrame(columns=self.col)\n",
    "      pred_test_y= pd.DataFrame(columns=self.col)\n",
    "\n",
    "      for (name, estimator) in self.estimators:\n",
    "        estimator.fit(X_train, y_train)\n",
    "        pred_test= estimator.predict(X_test)\n",
    "        pred_test_x[name]= pred_test[:,0]\n",
    "        pred_test_y[name]= pred_test[:,1]\n",
    "\n",
    "      return np.column_stack((np.mean(pred_test_x.values, axis=1), np.mean(pred_test_y.values, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUM_Ft0wpmzT"
   },
   "outputs": [],
   "source": [
    "stk= Voting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRj4yOgoQ0jo"
   },
   "outputs": [],
   "source": [
    "y_pred_train= stk.predict(x_train, y_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVI67pTJRVLr"
   },
   "outputs": [],
   "source": [
    "mean_euclidean_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdI__kUWpmzT"
   },
   "outputs": [],
   "source": [
    "y_pred_test= stk.predict(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVsGXDMypmzU"
   },
   "outputs": [],
   "source": [
    "mean_euclidean_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icOqmko5pmzU"
   },
   "outputs": [],
   "source": [
    "y_pred_blind= stk.predict(x_train, y_train, blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "it9iBhqO14Sb"
   },
   "outputs": [],
   "source": [
    "y_pred_blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m95yoAFL5OY6"
   },
   "outputs": [],
   "source": [
    "df_blind=pd.DataFrame(y_pred_blind)\n",
    "df_blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHx8iMLO5WCJ"
   },
   "outputs": [],
   "source": [
    "df_blind.index+=1\n",
    "df_blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jm35zKm72OdG"
   },
   "outputs": [],
   "source": [
    "df_blind.to_csv(\"./CUP/blind_prediction.csv\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8GTN0uQ3fql"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AcVgPcf4d41"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgk+D/oNHHoGTR8ysMMAHP",
   "collapsed_sections": [],
   "name": "Prediction_Blind_Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
